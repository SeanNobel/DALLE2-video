texts_dirs:
  root: /mnt/tsukuyomi/sensho/CelebV-Text/texts/
  details: face40_details_new/
  additional:
    action: action_dur/
    emotion: emotion/
    light_direction: light_dir/
    light_intensity: light_intensity/
    light_temp: light_color_temp/
  tokenized: data/texts/tokenized.pt
  embed: data/texts/embed.pt

videos_dirs:
  root: /mnt/tsukuyomi/sensho/CelebV-Text/videos/
  untar: celebvtext_6/
  preprocessed: data/videos/chunked2.h5
  embed: data/videos/embed.pt

seq_len: 5
fps: 30

clip_model: ViT-B/32

dim: 512
channels: 3

train_name: test
train_ratio: 0.8

# ==== CLIP ==== #
video_encoder:
  frame_size: 224
  patch_size: 56
  dim: ${dim}
  depth: 2
  in_channels: ${channels}

clip:
  batch_size: 64
  lr: 0.001
  lr_scheduler: multistep # cosine or multistep
  lr_multistep_mlstns: [0.4, 0.6, 0.8, 0.9]
  lr_step_gamma: 0.5
  epochs: 500
  reduction: mean
  init_temperature: 5.0
  cuda_id: 2
  num_workers: 1 # Probably best to set 1 when using h5py or DeepSpeed (from completely different reasons)

# ==== Decoder ==== #
unet1:
  dim: 64
  dim_mults: [1, 2, 4, 8]

unet2:
  dim: 8
  dim_mults: [1, 2, 4, 8, 16]

frame_sizes: [64, 128] # First Unet up to 128px, then Unet up to 256px
frame_numbers: [90, 90] # Not doing temporal super-resolution for now

timesteps: 1000

decoder:
  batch_size: 1 # 64
  epochs: 50
  cuda_id: 2
  num_workers: 1

decoder_trainer:
  lr: 3.0e-4
  wd: 1.0e-2
  use_ema: False
  ema_beta: 0.99
  ema_update_after_step: 1000
  ema_update_every: 10

deepspeed:
  gradient_accumulation_steps: 16

seed: 1234

log_level: INFO

use_wandb: False